{"cells":[{"cell_type":"markdown","id":"HeWgOD1uD1YP","metadata":{"id":"HeWgOD1uD1YP"},"source":["---\n","\n","Load libraries\n","\n","---"]},{"cell_type":"code","execution_count":1,"id":"FXrh9fPyMtwx","metadata":{"id":"FXrh9fPyMtwx","executionInfo":{"status":"ok","timestamp":1737464799688,"user_tz":-330,"elapsed":20830,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}}},"outputs":[],"source":["## Load libraries\n","import pandas as pd\n","import numpy as np\n","import sys\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import tensorflow as tf\n","from sklearn.metrics import confusion_matrix\n","plt.style.use('dark_background')\n","%matplotlib inline"]},{"cell_type":"markdown","id":"ttFTTWbqD4eQ","metadata":{"id":"ttFTTWbqD4eQ"},"source":["---\n","\n","Set printing precision\n","\n","---"]},{"cell_type":"code","execution_count":2,"id":"P3UMZJowDzo0","metadata":{"id":"P3UMZJowDzo0","executionInfo":{"status":"ok","timestamp":1737464799688,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}}},"outputs":[],"source":["np.set_printoptions(precision = 2)"]},{"cell_type":"markdown","id":"DIsc4Twv6UhG","metadata":{"id":"DIsc4Twv6UhG"},"source":["---\n","\n","Mount Google drive\n","\n","---"]},{"cell_type":"code","execution_count":null,"id":"0s0mudRDMxGf","metadata":{"id":"0s0mudRDMxGf"},"outputs":[],"source":["## Mount Google drive folder if running in Colab\n","if('google.colab' in sys.modules):\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount = True)\n","    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/EvenSem2025MAHE'\n","    DATA_DIR = DIR + '/Data/'\n","else:\n","    DATA_DIR = 'Data/'"]},{"cell_type":"markdown","id":"D6DHQ6D8CCH9","metadata":{"id":"D6DHQ6D8CCH9"},"source":["---\n","\n","Load MNIST Data\n","\n","---"]},{"cell_type":"code","execution_count":3,"id":"CRfIzvOsCDFR","metadata":{"id":"CRfIzvOsCDFR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737464802647,"user_tz":-330,"elapsed":2963,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}},"outputId":"2a84a193-61fc-48b8-89c8-38334b4949e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","MNIST set\n","---------------------\n","Number of training samples = 60000\n","Number of features = 784\n","Number of output labels = 10\n"]}],"source":["## Load MNIST data\n","(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n","\n","num_labels = len(np.unique(y_train))\n","num_features = X_train.shape[1]\n","num_samples = X_train.shape[0]\n","\n","# One-hot encode class labels\n","Y_train = tf.keras.utils.to_categorical(y_train)\n","Y_test = tf.keras.utils.to_categorical(y_test)\n","\n","# Normalize the samples (images) using the training data\n","xmax = np.amax(X_train) # 255\n","xmin = np.amin(X_train) # 0\n","X_train = (X_train - xmin) / (xmax - xmin) # all train features turn into a number between 0 and 1\n","X_test = (X_test - xmin) / (xmax - xmin)\n","\n","print('MNIST set')\n","print('---------------------')\n","print('Number of training samples = %d'%(num_samples))\n","print('Number of features = %d'%(num_features))\n","print('Number of output labels = %d'%(num_labels))"]},{"cell_type":"markdown","id":"BxG1YM906sEr","metadata":{"id":"BxG1YM906sEr"},"source":["---\n","\n","We consider a softmax classfier, which is a 1-layer neural network or a 0-hidden layer neural network, for a batch comprising $b$ samples represented as the $b\\times 784$-matrix $$\\mathbf{X} = \\begin{bmatrix}{\\mathbf{x}^{(0)}}^\\mathrm{T}\\\\{\\mathbf{x}^{(1)}}^\\mathrm{T}\\\\\\vdots\\\\{\\mathbf{x}^{(b-1)}}^\\mathrm{T}\\end{bmatrix}$$ with one-hot encoded true labels represented as the $b\\times 10$-matrix (10 possible categories) $$\\mathbf{Y}=\\begin{bmatrix}{\\mathbf{y}^{(0)}}^\\mathrm{T}\\\\{\\mathbf{y}^{(1)}}^\\mathrm{T}\\\\\\vdots\\\\{\\mathbf{y}^{(b-1)}}^\\mathrm{T}\\end{bmatrix}.$$\n","\n","The forward propagation for a generic sample in the batch seen as a $1\\times784$-object $\\mathbf{x}^\\mathrm{T}$ with the bias feature $1$ added is presented below:\n","\n","$$\\small\\begin{align*}\n","\\boxed{\\underbrace{\\mathbf{x}_B^\\mathrm{T}}_{1\\times785}=\\begin{bmatrix}\\mathbf{x}^\\mathrm{T}&1\\end{bmatrix}}&\\rightarrow\\boxed{\\underbrace{{\\mathbf{z}}^\\mathrm{T}}_{1\\times 10} = \\underbrace{\\mathbf{x}_B^\\mathrm{T}}_{1\\times785}\\underbrace{{\\mathbf{W}}}_{785\\times10}}\\rightarrow\\boxed{\\underbrace{{\\mathbf{a}}^\\mathrm{T}}_{1\\times10}=\\text{softmax}\\left(\\underbrace{{\\mathbf{z}}^\\mathrm{T}}_{1\\times10}\\right)}\\rightarrow\\boxed{L = \\sum\\limits_{k=0}^9-y_k\\log\\left(\\hat{y}_k\\right)}.\n","\\end{align*}$$\n","\n","The forward propagation for the same generic sample seen as a $784$-vector $\\mathbf{x}$ with the bias feature $1$ added is presented below (note that the weight matrix has the same name $\\mathbf{W}$ as above for simplicity even though it should show up as $\\mathbf{W}^\\mathrm{T}$):\n","\n","$$\\small\\begin{align*}\n","\\boxed{\\underbrace{\\mathbf{x}_B}_{785}=\\begin{bmatrix}\\mathbf{x}\\\\1\\end{bmatrix}}&\\rightarrow\\boxed{\\underbrace{\\mathbf{z}}_{10} = \\underbrace{\\mathbf{W}}_{10\\times785}\\underbrace{\\mathbf{x}_B}_{785}}\\rightarrow\\boxed{\\underbrace{\\mathbf{a}}_{10}=\\text{softmax}\\left(\\underbrace{\\mathbf{z}}_{10}\\right)}\\rightarrow\\boxed{L = \\sum\\limits_{k=0}^9-y_k\\log\\left(\\hat{y}_k\\right)}.\\end{align*}$$\n","\n","We will derive the update rule for the weights matrix $\\mathbf{W}$ using the setup above.\n","\n","\n","The average crossentropy (CCE) loss for the batch is:$$\\begin{align*}L &=\\frac{1}{b}\\left[L_0+L_1+\\cdots+L_{b-1}\\right]\\\\&=\\frac{1}{b}\\left[\\sum\\limits_{k=0}^9{\\color{yellow}-}y_k^{(0)}\\log\\left(\\hat{y}^{(0)}_k\\right)+\\sum\\limits_{k=0}^9{\\color{yellow}-}y_k^{(1)}\\log\\left(\\hat{y}^{(1)}_k\\right)+\\cdots+\\sum\\limits_{k=0}^9{\\color{yellow}-}y_k^{(b-1)}\\log\\left(\\hat{y}^{(b-1)}_k\\right)\\right]\\\\&=\\frac{1}{b}\\left[{\\color{yellow}-}{\\mathbf{y}^{(0)}}^\\mathrm{T}\\log\\left({\\hat{\\mathbf{y}}^{(0)}}\\right)+{\\color{yellow}-}{\\mathbf{y}^{(1)}}^\\mathrm{T}\\log\\left({\\hat{\\mathbf{y}}^{(1)}}\\right)+\\cdots+{\\color{yellow}-}{\\mathbf{y}^{(b-1)}}^\\mathrm{T}\\log\\left({\\hat{\\mathbf{y}}^{(b-1)}}\\right)\\right].\\end{align*}$$\n","\n","The computational graph for the samples, each at a time treated as a $785$-vector, in the batch are presented below where the weights matrix has shape $10\\times 785.$\n","\n","$\\hspace{1.5in}\\begin{align*}L_0\\\\{\\color{yellow}\\downarrow}\\\\ \\hat{\\mathbf{y}}^{(0)} &= \\mathbf{a}^{(0)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{z}^{(0)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{W}\\end{align*}$$\\hspace{0.25in}\\begin{align*}L_1\\\\{\\color{yellow}\\downarrow}\\\\ \\hat{\\mathbf{y}}^{(1)} &= \\mathbf{a}^{(1)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{z}^{(1)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{W}\\end{align*}$$\\qquad\\cdots\\qquad$$\\begin{align*} L_{b-1}\\\\{\\color{yellow}\\downarrow}\\\\ \\hat{\\mathbf{y}}^{(b-1)} &= \\mathbf{a}^{(b-1)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{z}^{(b-1)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{W}\\end{align*}$\n","\n","The gradient of the average batch loss w.r.t. the weights is:\n","$$\\small\\begin{align*}\\Rightarrow \\nabla_\\mathbf{W}(L) &=\\frac{1}{b}\\left[\\nabla_\\mathbf{W}(L_0)+\\nabla_\\mathbf{W}(L_1)+\\cdots+\\nabla_\\mathbf{W}(L_{b-1})\\right]\\end{align*}$$\n","which by chain rule can be written as:\n","\n","$$\\small\\begin{align*}\\Rightarrow \\nabla_\\mathbf{W}(L) &= \\frac{1}{b}\\left(\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(0)}\\right) \\times\\nabla_{\\mathbf{z}^{(0)}}\\left(\\hat{\\mathbf{y}}^{(0)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(0)}}(L_0)\\right]}_{\\nabla_\\mathbf{W}(L_0)}+\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(1)}\\right) \\times\\nabla_{\\mathbf{z}^{(1)}}\\left(\\hat{\\mathbf{y}}^{(1)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(1)}}(L_1)\\right]}_{\\nabla_\\mathbf{W}(L_1)}+\\cdots+\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(b-1)}\\right) \\times\\nabla_{\\mathbf{z}^{(b-1)}}\\left(\\hat{\\mathbf{y}}^{(b-1)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(b-1)}}(L_{b-1})\\right]}_{\\nabla_\\mathbf{W}(L_{b-1})}\\right)\\\\&=\\frac{1}{b}\\left(\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(0)}\\right) \\times\\nabla_{\\mathbf{z}^{(0)}}\\left({\\mathbf{a}}^{(0)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(0)}}(L_0)\\right]}_{\\nabla_\\mathbf{W}(L_0)}+\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(1)}\\right) \\times\\nabla_{\\mathbf{z}^{(1)}}\\left({\\mathbf{a}}^{(1)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(1)}}(L_1)\\right]}_{\\nabla_\\mathbf{W}(L_1)}+\\cdots+\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(b-1)}\\right) \\times\\nabla_{\\mathbf{z}^{(b-1)}}\\left(\\hat{\\mathbf{y}}^{(b-1)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(b-1)}}(L_{b-1})\\right]}_{\\nabla_\\mathbf{W}(L_{b-1})}\\right)\\\\&=\\frac{1}{b}\\sum_{i=0}^{b-1}\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(i)}\\right) \\times\\nabla_{\\mathbf{z}^{(i)}}\\left({\\mathbf{a}}^{(i)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(i)}}(L_i)\\right]\\\\&=\\frac{1}{b}\\sum_{i=0}^{b-1}\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{W}{\\mathbf{x}^{(i)}_B}\\right) \\times\\nabla_{\\mathbf{z}^{(i)}}\\left(\\text{softmax}\\left({\\mathbf{z}}^{(i)}\\right)\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(i)}}\\left(-{\\mathbf{y}^{(i)}}^\\mathrm{T}\\log\\left(\\hat{\\mathbf{y}}^{(i)}\\right)\\right)\\right],\\end{align*}$$\n","which can be written as\n","\n","$$\\begin{align*}\\nabla_{\\mathbf{W}}(L) &= \\dfrac{1}{b}\\displaystyle\\sum_{i=0}^{b-1}\\underbrace{\\begin{bmatrix}\\boxed{{\\mathbf{x}^{(i)}_B}\\ \\pmb{0}\\ \\pmb{0}\\ \\ldots\\ \\pmb{0}}&&&&\\\\\\\\&\\boxed{\\pmb{0}\\ {\\mathbf{x}^{(i)}_B}\\ \\pmb{0}\\ \\ldots\\ \\pmb{0}}&&&\\\\&\\hspace{1cm}\\ddots&&&\\\\&&\\hspace{-0.5cm}\\ddots&&\\\\&&&\\boxed{\\pmb{0}\\ \\pmb{0}\\ \\ldots\\ \\pmb{0}\\ {\\mathbf{x}^{(i)}_B}}&\\end{bmatrix}}_{\\color{cyan}{\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(i)}\\right)=\\nabla_\\mathbf{W}\\left(\\mathbf{W}{\\mathbf{x}^{(i)}_B}\\right):\\ 10\\times785\\times10}}\\underbrace{\\begin{bmatrix}a^{(i)}_0 (1 - a^{(i)}_0) & -a^{(i)}_0 a^{(i)}_1 & \\cdots & -a^{(i)}_0 a^{(i)}_9\\\\-a^{(i)}_1 a^{(i)}_0 & a^{(i)}_1 (1 - a^{(i)}_1) & \\cdots & -a^{(i)}_1 a^{(i)}_9\\\\\\vdots & \\vdots & \\ddots & \\vdots\\\\-a^{(i)}_9 a^{(i)}_0 & -a^{(i)}_9 a^{(i)}_1 & \\cdots & a^{(i)}_9 (1 - a^{(i)}_9)\\end{bmatrix}}_{\\color{cyan}{\\nabla_{\\mathbf{z}^{(i)}}\\left({\\mathbf{a}}^{(i)}\\right) = \\nabla_{\\mathbf{z}^{(i)}}\\left(\\text{softmax}\\left({\\mathbf{z}}^{(i)}\\right)\\right):\\ 10\\times10}}\\underbrace{\\begin{bmatrix}-\\frac{y^{(i)}_0}{\\hat{y}^{(i)}_0}\\\\-\\frac{y^{(i)}_1}{\\hat{y}^{(i)}_1}\\\\\\vdots\\\\-\\frac{y^{(i)}_9}{\\hat{y}^{(i)}_9}\\end{bmatrix}}_{\\color{cyan}{\\nabla_{\\hat{\\mathbf{y}}^{(i)}}(L_i)=\\nabla_{\\hat{\\mathbf{y}}^{(i)}}\\left(-{\\mathbf{y}^{(i)}}^\\mathrm{T}\\log\\left(\\hat{\\mathbf{y}}^{(i)}\\right)\\right):\\ 10\\times1}}\\end{align*}$$\n","\n","The forward and backward propagation showing the gradient flow for a generic sample is shown below:\n","\n","![](https://1drv.ms/i/c/37720f927b6ddc34/IQS3b-biQ4W9QpCtJzaZnyCoAQ8_r9i707rpOE1O9I0yntM?width=686&height=93)\n","\n","$$\\begin{align*}\\nabla_{\\mathbf{W}}(L) &=\\dfrac{1}{b}\\displaystyle\\sum_{i=0}^{b-1}\\underbrace{\\begin{bmatrix}a^{(i)}_0 (1 - a^{(i)}_0) & -a^{(i)}_0 a^{(i)}_1 & \\cdots & -a^{(i)}_0 a^{(i)}_9\\\\-a^{(i)}_1 a^{(i)}_0 & a^{(i)}_1 (1 - a^{(i)}_1) & \\cdots & -a^{(i)}_1 a^{(i)}_9\\\\\\vdots & \\vdots & \\ddots & \\vdots\\\\-a^{(i)}_9 a^{(i)}_0 & -a^{(i)}_9 a^{(i)}_1 & \\cdots & a^{(i)}_9 (1 - a^{(i)}_9)\\end{bmatrix}}_{\\color{cyan}{=\\left(\\mathbf{I}-{\\mathbf{a}^{(i)}}^\\mathrm{T}\\right)\\otimes\\mathbf{a}^{(i)}}}\\underbrace{\\begin{bmatrix}-\\frac{y^{(i)}_0}{\\hat{y}^{(i)}_0} \\\\\n","-\\frac{y^{(i)}_1}{\\hat{y}^{(i)}_1}\\\\\\vdots\\\\-\\frac{y^{(i)}_9}{\\hat{y}^{(i)}_9}\\end{bmatrix}}_{\\color{cyan}{=-\\frac{\\mathbf{y}^{(i)}}{\\hat{\\mathbf{y}}^{(i)}}}}{\\mathbf{x}^{(i)}_B}^\\mathrm{T}.\\end{align*}$$\n","\n","We can write the gradient in the following way for efficient coding purposes: $$\\nabla_\\mathbf{W}(L) = \\frac{1}{b}\\sum_{i=0}^{b-1}\\left[\\left(\\mathbf{I}-{\\mathbf{a}^{(i)}}^\\mathrm{T}\\right)\\otimes\\mathbf{a}^{(i)}\\right]\\left[-\\frac{\\mathbf{y}^{(i)}}{\\hat{\\mathbf{y}}^{(i)}}\\right]{\\mathbf{x}^{(i)}_B}^\\mathrm{T}.$$\n","\n","\n","It can be seen that the gradient object has shape $(10\\times 10)\\times(10\\times1)\\times(1\\times785)=10\\times785,$ which is the same shape as the weights matrix $\\mathbf{W}.$ However, our derivation here assumed that the samples are seen as column vectors of the data matrix. The original data matrix has the samples arranged as rows which corresponded to the weights matrix of shape $785\\times10.$ In order to get the gradient w.r.t. that weights matrix, we have to transpose this expression resulting in the update $$\\nabla_\\mathbf{W}(L) = \\frac{1}{b}\\sum_{i=0}^{b-1}\\underbrace{\\mathbf{x}^{(i)}_B}_{\\color{yellow}{785\\times1}}\\underbrace{\\underbrace{\\left[-\\frac{{\\mathbf{y}^{(i)}}^\\mathrm{T}}{{\\hat{\\mathbf{y}}^{(i)}}^\\mathrm{T}}\\right]}_{\\color{magenta}{\\text{output side gradient of softmax layer: }1\\times10}}\\underbrace{\\left[\\left(\\mathbf{I}-{\\mathbf{a}^{(i)}}\\right)\\otimes{\\mathbf{a}^{(i)}}^\\mathrm{T}\\right]}_{\\color{magenta}{\\text{local gradient of softmax layer: }10\\times10}}}_{\\color{yellow}{\\text{output side gradient of dense layer: }1\\times10}}.$$\n","\n","\n","\n","Note that when regularization is applied to the weights using a regularization strength $\\lambda,$ then the regularization loss gets added to the data loss to give the total loss for the batch as follows: $$\\begin{align*}L &= L_\\text{data}+L_\\text{reg}\\\\&=\\frac{1}{b}\\left[L_0+L_1+\\cdots+L_{b-1}\\right]+\\lambda\\left[{\\mathbf{w}^{(0)}}^\\mathrm{T}\\mathbf{w}^{(0)}+{\\mathbf{w}^{(1)}}^\\mathrm{T}\\mathbf{w}^{(1)}+\\cdots+{\\mathbf{w}^{(783)}}^\\mathrm{T}\\mathbf{w}^{(783)}\\right].\\end{align*}$$\n","Note that the last row of the weights matrix $\\mathbf{W},$ which comprises the bias values, are not included in the regularization loss.\n","\n","The gradient w.r.t. the weights matrix $\\mathbf{W}$ now also includes the gradient w.r.t. the regularization loss as follows: $$\\begin{align*}\\nabla_\\mathbf{W}(L)&=\\nabla_\\mathbf{W}\\left(\\frac{1}{b}\\left[L_0+L_1+\\cdots+L_{b-1}\\right]\\right)+\\lambda\\nabla_\\mathbf{W}\\left(L_\\text{reg}\\right)\\\\&=\\underbrace{\\frac{1}{b}\\sum_{i=0}^{b-1}{\\mathbf{x}^{(i)}_B}\\left[-\\frac{{\\mathbf{y}^{(i)}}^\\mathrm{T}}{{\\hat{\\mathbf{y}}^{(i)}}^\\mathrm{T}}\\right]\\left[\\left(\\mathbf{I}-{\\mathbf{a}^{(i)}}\\right)\\otimes{\\mathbf{a}^{(i)}}^\\mathrm{T}\\right]}_{\\text{data gradient}}+\\lambda\\underbrace{\\begin{bmatrix}2{\\mathbf{w}^{(0)}}^\\mathrm{T}\\\\2{\\mathbf{w}^{(1)}}^\\mathrm{T}\\\\\\vdots\\\\2{\\mathbf{w}^{(783)}}^\\mathrm{T}\\\\\\pmb{0}\\end{bmatrix}}_{\\text{regularization gradient}}.\\end{align*}$$\n","\n","\n","---"]},{"cell_type":"markdown","id":"oKggGU1vRBif","metadata":{"id":"oKggGU1vRBif"},"source":["---\n","\n","A generic layer class with forward and backward methods\n","\n","----"]},{"cell_type":"code","execution_count":4,"id":"tZHmwpk4Q404","metadata":{"id":"tZHmwpk4Q404","executionInfo":{"status":"ok","timestamp":1737464802647,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}}},"outputs":[],"source":["class Layer:\n","  def __init__(self):\n","    self.input = None\n","    self.output = None\n","\n","  def forward(self, input):\n","    pass\n","\n","  def backward(self, output_gradient, learning_rate):\n","    pass"]},{"cell_type":"markdown","id":"s6nr7yGIRsa3","metadata":{"id":"s6nr7yGIRsa3"},"source":["---\n","\n","CCE loss and its gradient for the batch samples\n","\n","---"]},{"cell_type":"code","execution_count":5,"id":"ivzPpy3FRtQE","metadata":{"id":"ivzPpy3FRtQE","executionInfo":{"status":"ok","timestamp":1737464802648,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}}},"outputs":[],"source":["## Define the loss function and its gradient\n","def cce(Y, Yhat):\n","  return(np.mean(np.sum(-Y*np.log(Yhat), axis = 1), axis = 0))\n","  #TensorFlow in-built function for categorical crossentropy loss\n","  #cce = tf.keras.losses.CategoricalCrossentropy()\n","  #return(cce(Y, Yhat).numpy())\n","\n","def cce_gradient(Y, Yhat):\n","  return(-Y/Yhat)"]},{"cell_type":"markdown","id":"t_hwSUUiVlWD","metadata":{"id":"t_hwSUUiVlWD"},"source":["---\n","\n","Softmax activation layer class\n","\n","\n","---"]},{"cell_type":"code","execution_count":6,"id":"6bVplzEcMWlP","metadata":{"id":"6bVplzEcMWlP","executionInfo":{"status":"ok","timestamp":1737464802648,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}}},"outputs":[],"source":["## Softmax activation layer class\n","class Softmax(Layer):\n","  def forward(self, input):\n","    self.input = input\n","    self.output = tf.nn.softmax(self.input, axis = 1).numpy()\n","\n","  def backward(self, output_gradient, learning_rate = None):\n","    I = np.identity(self.output.shape[1])\n","    local_gradient = (I - self.output[:, :, np.newaxis]) * self.output[:, np.newaxis, :]\n","    return(np.einsum('ij,ijk->ik', output_gradient, local_gradient))"]},{"cell_type":"markdown","id":"HCDIPQkp7JmN","metadata":{"id":"HCDIPQkp7JmN"},"source":["---\n","\n","Dense layer class\n","\n","---"]},{"cell_type":"code","execution_count":14,"id":"aLs-dsgv7Nxl","metadata":{"id":"aLs-dsgv7Nxl","executionInfo":{"status":"ok","timestamp":1737466038123,"user_tz":-330,"elapsed":491,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}}},"outputs":[],"source":["## Dense layer class\n","class Dense(Layer):\n","    def __init__(self, input_size, output_size, reg_strength = 0.0):\n","        self.weights = 0.01*np.random.randn(input_size+1, output_size) # bias trick\n","        self.weights[-1, :] = 0.01 # set all bias values to the same nonzero constant\n","        self.reg_strength = reg_strength # lambda\n","        self.reg_loss = None\n","\n","    def forward(self, input):\n","        self.input = np.hstack([input, np.ones((input.shape[0], 1))]) # bias trick\n","        # Forward propagation\n","        self.output= np.dot(self.input, self.weights)\n","        # Calculate regularization loss\n","        self.reg_loss = self.reg_strength * np.sum(self.weights[:-1, :] * self.weights[:-1, :]) # lambda * sum of coefficients (exlcuding bias row)\n","\n","    def backward(self, output_gradient, learning_rate):\n","        # Calculate gradient w.r.t. dense layer weights from all inputs\n","        weights_gradient = (1/output_gradient.shape[0]) * (np.einsum('ij,ik->jk', self.input, output_gradient))\n","        # Add the regularization gradient here\n","        weights_gradient += 2 * self.reg_strength * np.vstack([self.weights[:-1, :], np.zeros((1, self.weights.shape[1]))]) # lambda * reg_gradient (keep bias row in weight matrix as 0)\n","        # Update weights for dense layer\n","        self.weights = self.weights + learning_rate * (-weights_gradient)"]},{"cell_type":"markdown","id":"Pr2pX28071bj","metadata":{"id":"Pr2pX28071bj"},"source":["---\n","\n","Function to generate sample indices for batch processing according to batch size\n","\n","---"]},{"cell_type":"code","execution_count":11,"id":"z7TmsRrw72LB","metadata":{"id":"z7TmsRrw72LB","executionInfo":{"status":"ok","timestamp":1737465674046,"user_tz":-330,"elapsed":390,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}}},"outputs":[],"source":["## Function to generate sample indices for batch processing according to batch size\n","def generate_batch_indices(num_samples, batch_size):\n","  # Reorder sample indices\n","  reordered_sample_indices = np.random.choice(num_samples, num_samples, replace = False)\n","  # Generate batch indices for batch processing\n","  batch_indices = np.split(reordered_sample_indices, np.arange(batch_size, len(reordered_sample_indices), batch_size))\n","  return(batch_indices)"]},{"cell_type":"markdown","id":"XNNMRK7u75l7","metadata":{"id":"XNNMRK7u75l7"},"source":["---\n","\n","Example generation of batch indices\n","\n","---"]},{"cell_type":"code","execution_count":12,"id":"Q34Ulk_v78bv","metadata":{"id":"Q34Ulk_v78bv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737465675031,"user_tz":-330,"elapsed":2,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}},"outputId":"a107ea49-fc4a-4b26-f91d-d5c4fab33b11"},"outputs":[{"output_type":"stream","name":"stdout","text":["[array([ 4, 57, 31,  6, 18, 13, 26,  3, 52, 35, 16, 63, 39, 20, 41, 27]), array([ 7, 24, 47, 49, 48, 11, 46, 17,  0, 23,  1, 37, 14, 50,  9, 22]), array([19, 29, 40, 59, 34, 32, 45, 44, 36, 51, 62,  5, 56, 61,  2, 42]), array([10, 54, 25, 28, 38, 30, 12, 43, 33, 60, 53,  8, 58, 55, 21, 15])]\n"]}],"source":["## Example generation of batch indices\n","batch_size = 16\n","batch_indices = generate_batch_indices(64, batch_size)\n","print(batch_indices)"]},{"cell_type":"markdown","id":"BzW-2lIo8As4","metadata":{"id":"BzW-2lIo8As4"},"source":["---\n","\n","Train the 1-layer neural (softmax) neural network using batch training with batch size = 100\n","\n","---"]},{"cell_type":"code","execution_count":17,"id":"Jzk8_9Xl8Bdu","metadata":{"id":"Jzk8_9Xl8Bdu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737466263721,"user_tz":-330,"elapsed":98433,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}},"outputId":"b83a158b-0c9e-427f-cc84-cc66e838d894"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: train loss = 1.780980, test loss = 1.669516\n","Epoch 2: train loss = 1.685721, test loss = 1.664577\n","Epoch 3: train loss = 1.682606, test loss = 1.662191\n","Epoch 4: train loss = 1.680302, test loss = 1.659596\n","Epoch 5: train loss = 1.678462, test loss = 1.658400\n","Epoch 6: train loss = 1.676799, test loss = 1.656713\n","Epoch 7: train loss = 1.675723, test loss = 1.655193\n","Epoch 8: train loss = 1.674522, test loss = 1.654460\n","Epoch 9: train loss = 1.673769, test loss = 1.654195\n","Epoch 10: train loss = 1.673048, test loss = 1.654619\n","Epoch 11: train loss = 1.672631, test loss = 1.653468\n","Epoch 12: train loss = 1.672058, test loss = 1.652994\n","Epoch 13: train loss = 1.671746, test loss = 1.652255\n","Epoch 14: train loss = 1.671364, test loss = 1.653060\n","Epoch 15: train loss = 1.671230, test loss = 1.651338\n","Epoch 16: train loss = 1.671171, test loss = 1.651391\n","Epoch 17: train loss = 1.670757, test loss = 1.651419\n","Epoch 18: train loss = 1.670732, test loss = 1.651658\n","Epoch 19: train loss = 1.670671, test loss = 1.651567\n","Epoch 20: train loss = 1.670555, test loss = 1.650896\n","Epoch 21: train loss = 1.670458, test loss = 1.651617\n","Epoch 22: train loss = 1.670497, test loss = 1.651525\n","Epoch 23: train loss = 1.670413, test loss = 1.650716\n","Epoch 24: train loss = 1.670359, test loss = 1.651281\n","Epoch 25: train loss = 1.670324, test loss = 1.651195\n","Epoch 26: train loss = 1.670143, test loss = 1.652467\n","Epoch 27: train loss = 1.670234, test loss = 1.650836\n","Epoch 28: train loss = 1.670167, test loss = 1.650763\n","Epoch 29: train loss = 1.670298, test loss = 1.651097\n","Epoch 30: train loss = 1.670096, test loss = 1.651097\n","Epoch 31: train loss = 1.670019, test loss = 1.650938\n","Epoch 32: train loss = 1.670258, test loss = 1.651174\n","Epoch 33: train loss = 1.670174, test loss = 1.650800\n","Epoch 34: train loss = 1.670285, test loss = 1.650815\n","Epoch 35: train loss = 1.670293, test loss = 1.650657\n","Epoch 36: train loss = 1.670214, test loss = 1.651042\n","Epoch 37: train loss = 1.670211, test loss = 1.650587\n","Epoch 38: train loss = 1.670215, test loss = 1.650487\n","Epoch 39: train loss = 1.670090, test loss = 1.651218\n","Epoch 40: train loss = 1.670231, test loss = 1.650606\n","Epoch 41: train loss = 1.670181, test loss = 1.651137\n","Epoch 42: train loss = 1.670272, test loss = 1.651173\n","Epoch 43: train loss = 1.670213, test loss = 1.650837\n","Epoch 44: train loss = 1.670300, test loss = 1.650411\n","Epoch 45: train loss = 1.670209, test loss = 1.650622\n","Epoch 46: train loss = 1.670214, test loss = 1.652297\n","Epoch 47: train loss = 1.670179, test loss = 1.651004\n","Epoch 48: train loss = 1.670241, test loss = 1.650813\n","Epoch 49: train loss = 1.670128, test loss = 1.650965\n","Epoch 50: train loss = 1.670170, test loss = 1.651612\n"]}],"source":["## Train the 1-layer neural network using batch training with batch size = 100\n","learning_rate = 1e-02\n","batch_size = 100\n","nepochs = 50\n","reg_strength = 0.25\n","# Create empty array to store training losses over each epoch\n","loss_train_epoch = np.empty(nepochs, dtype = np.float64)\n","# Create empty array to store test losses over each epoch\n","loss_test_epoch = np.empty(nepochs, dtype = np.float64)\n","\n","# Neural network architecture ()\n","dlayer1 = Dense(num_features, num_labels, reg_strength) # define dense layer 1\n","softmax = Softmax() # define softmax activation layer\n","\n","# Steps: run over each sample in the batch, calculate loss, gradient of loss,\n","# and update weights.\n","epoch = 0\n","# Run over each epoch\n","while epoch < nepochs:\n","  # Generate the batches\n","  batch_indices = generate_batch_indices(num_samples, batch_size)\n","  loss = 0\n","  # Run over each batch of samples\n","  for b in range(len(batch_indices)):\n","    # Forward prop starts here\n","    dlayer1.forward(X_train[batch_indices[b], :]) # forward prop dense layer 1\n","    softmax.forward(dlayer1.output) # forward prop softmax activation layer\n","    loss += cce(Y_train[batch_indices[b], :], softmax.output)\n","    # Add the regularization losses\n","    loss += dlayer1.reg_loss\n","    # Forward prop ends and backward prop starts here\n","    grad = cce_gradient(Y_train[batch_indices[b], :], softmax.output)\n","    grad = softmax.backward(grad)\n","    grad = dlayer1.backward(grad, learning_rate)\n","  # Calculate the average training loss for the current epoch\n","  loss_train_epoch[epoch] = loss/len(batch_indices)\n","\n","  # Forward propagation for test data\n","  dlayer1.forward(X_test)\n","  softmax.forward(dlayer1.output)\n","\n","  # Calculate test data loss plus regularization loss\n","  loss_test_epoch[epoch] =  cce(Y_test, softmax.output) + dlayer1.reg_loss\n","\n","  print('Epoch %d: train loss = %f, test loss = %f'%(epoch+1, loss_train_epoch[epoch], loss_test_epoch[epoch]))\n","  epoch = epoch + 1"]},{"cell_type":"markdown","id":"8GWSFNvg8arf","metadata":{"id":"8GWSFNvg8arf"},"source":["---\n","\n","Plot training and test loss vs. epoch\n","\n","---"]},{"cell_type":"code","execution_count":18,"id":"S72SmRqD8dca","metadata":{"id":"S72SmRqD8dca","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"ok","timestamp":1737466308741,"user_tz":-330,"elapsed":532,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}},"outputId":"b90c7786-e9c0-43b7-f9bd-aa8a8c391e28"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 400x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["## Plot train and test loss as a function of epoch:\n","fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n","fig.tight_layout(pad = 4.0)\n","ax.plot(loss_train_epoch, 'b', label = 'Train')\n","ax.plot(loss_test_epoch, 'r', label = 'Test')\n","ax.set_xlabel('Epoch', fontsize = 12)\n","ax.set_ylabel('Loss value', fontsize = 12)\n","ax.legend()\n","ax.set_title('Loss vs. Epoch for Softmax Classifier', fontsize = 14);"]},{"cell_type":"markdown","id":"oqR5Q5qS8mWm","metadata":{"id":"oqR5Q5qS8mWm"},"source":["---\n","\n","Assess model performance on test data\n","\n","---"]},{"cell_type":"code","execution_count":19,"id":"Su24oMSJTxEb","metadata":{"id":"Su24oMSJTxEb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737466331914,"user_tz":-330,"elapsed":389,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}},"outputId":"68412813-3a3e-4793-8044-e7451b434925"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on test data = 81.47\n","[[ 933    0    7   10    2    2   19    2    5    0]\n"," [   0 1107   14    2    0    0    3    0    9    0]\n"," [  18   83  803   30   26    0   18   22   30    2]\n"," [   5   30   26  883    1    3    8   23   22    9]\n"," [   2   29    5    0  861    0   16    5    4   60]\n"," [  26   94    8  248   30  369   28   41   25   23]\n"," [  27   31   23    1   20   12  842    1    1    0]\n"," [   3   67   22    1   13    0    1  899    4   18]\n"," [  18   73   19  103   13    3   14   19  687   25]\n"," [  22   30   12   13   94    0    1   64   10  763]]\n"]}],"source":["## Assess model performance on test data\n","dlayer1.forward(X_test)\n","#alayer1.forward(dlayer1.output)\n","#dlayer2.forward(alayer1.output)\n","softmax.forward(dlayer1.output)\n","ypred = np.argmax(softmax.output, axis = 1)\n","ytrue = np.argmax(Y_test, axis = 1)\n","print('Accuracy on test data = %3.2f'%(np.mean(ytrue == ypred)*100))\n","# Print confusion matrix\n","print(confusion_matrix(ytrue, ypred))"]},{"cell_type":"code","source":["## Plot a random test sample with its predicted label printed above the plot\n","test_index = np.random.choice(X_test.shape[0])\n","fig, ax = plt.subplots(1, 1, figsize = (2, 2))\n","print(f'Image classified as {ypred[test_index]}')\n","ax.imshow(tf.reshape(X_test[test_index], [28, 28]).numpy(), cmap = 'gray');"],"metadata":{"id":"GO70lwOTuH74","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"ok","timestamp":1737466339658,"user_tz":-330,"elapsed":408,"user":{"displayName":"Sathvik Nayak","userId":"11086093538711749215"}},"outputId":"eaef397e-dd00-46d5-8ef1-01ad09e01935"},"id":"GO70lwOTuH74","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Image classified as 4\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 200x200 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"required_libs":[]},"nbformat":4,"nbformat_minor":5}